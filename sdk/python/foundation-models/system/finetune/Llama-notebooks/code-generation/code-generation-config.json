{
    "token_count_per_sample": false,
    "generator_config": {
        "return_full_text": true,
        "max_new_tokens": 500,
        "do_sample": false,
        "temperature": 0.0,
        "top_p": 1.0
    }
}